{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_train_params.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GeWSUts3wrp",
        "outputId": "0086c219-7f83-436e-8eba-e0ff52e84e5c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "-4QYE-7y3034",
        "outputId": "5eef7255-dcce-4de5-a09a-d468c33b4446"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-35a75220-0c71-42d2-b76d-828b3d0a93af\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-35a75220-0c71-42d2-b76d-828b3d0a93af\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Astar.py to Astar.py\n",
            "Saving cnn.py to cnn.py\n",
            "Saving cube_model_naive.py to cube_model_naive.py\n",
            "Saving train.py to train.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Astar.py': b'\"\"\"Implementation of A* heuristic search algorithm\"\"\"\\nimport numpy as np\\nimport heapq\\nimport jax\\nfrom collections import deque\\nfrom functools import partial\\nfrom time import time\\n\\nfrom cube_model_naive import Cube\\n# from cnn import cnn_init, cnn_apply\\n\\n\\ndef astar(state, params, approximator):\\n    # (value, steps, stateID, actions)\\n    v = approximator(params, np.array([state]))\\n    uid = 0\\n    node_states = {uid: state}\\n    node_values = {uid: float(v)}\\n    H = [(-float(v), 0, uid, tuple())]\\n    heapq.heapify(H)\\n\\n    _cube = Cube()\\n    i = 0\\n    while i < 1000:\\n        _, steps, current_id, actions = heapq.heappop(H)\\n        current = node_states[current_id]\\n        children, _ = Cube.expand_state(current)\\n        children_values = approximator(params, children)\\n        for cval, cstate, cact in zip(children_values, children, range(12)):\\n            uid += 1\\n            node_states[uid] = cstate\\n            node_values[uid] = (-float(cval) + steps + 1)\\n            c_actions = actions + (cact,)\\n            if _cube.is_terminal(cstate):\\n                return c_actions\\n            heapq.heappush(H, (node_values[uid], steps + 1, uid, c_actions))\\n        i += 1\\n    return ()\\n',\n",
              " 'cnn.py': b'import numpy as np\\nimport jax\\nimport jax.numpy as jnp\\nfrom jax.experimental.stax import Conv, Relu, Flatten, Dense, serial\\nfrom jax.nn.initializers import glorot_normal, normal\\nfrom jax.lax import conv_general_dilated\\nfrom jax.nn import relu\\n\\n\\ndef conv_net():\\n    out_dim = 1\\n    dim_nums = (\"NHWC\", \"HWIO\", \"NHWC\")\\n\\n    # Primary convolutional layer.\\n    conv_channels = 8\\n    conv_init, conv_apply = Conv(out_chan=conv_channels, filter_shape=(3,3),\\n                                 strides=(1,3), padding=[(0,0), (0,0)])\\n    # Group all possible pairs.\\n    pair_channels, filter_shape = 64, (1, 2)\\n\\n    # Forward pass.\\n    serial_init, serial_apply = serial(Flatten, Dense(512), Relu, Dense(out_dim))\\n\\n    def init_fun(rng, input_shape):\\n        rng, conv_rng, serial_rng = jax.random.split(rng, num=3)\\n\\n        # Primary convolutional layer.\\n        conv_shape, conv_params = conv_init(conv_rng, (-1,) + input_shape)\\n\\n        # Grouping all possible pairs.\\n        kernel_shape = [filter_shape[0], filter_shape[1], conv_channels, pair_channels]\\n        bias_shape = [1, 1, 1, pair_channels]\\n        W_init = glorot_normal(in_axis=2, out_axis=3)\\n        b_init = normal(1e-6)\\n        k1, k2 = jax.random.split(rng)\\n        W, b = W_init(k1, kernel_shape), b_init(k2, bias_shape)\\n        pair_shape = conv_shape[:2] + (15,) + (pair_channels,)\\n        pair_params = (W, b)\\n\\n        # Forward pass.\\n        serial_shape, serial_params = serial_init(serial_rng, pair_shape)\\n        params = [conv_params, pair_params, serial_params]\\n        return serial_shape, params\\n\\n    def apply_fun(params, inputs):\\n        conv_params, pair_params, serial_params = params\\n\\n        # Apply the primary convolutional layer.\\n        conv_out = conv_apply(conv_params, inputs)\\n        conv_out = relu(conv_out)\\n\\n        # Group all possible pairs.\\n        W, b = pair_params\\n        stride, pad = (1,1), ((0,0),(0,0))\\n        pair_1 = conv_general_dilated(conv_out, W, stride, pad, (1,1), (1,1), dim_nums) + b\\n        pair_2 = conv_general_dilated(conv_out, W, stride, pad, (1,1), (1,2), dim_nums) + b\\n        pair_3 = conv_general_dilated(conv_out, W, stride, pad, (1,1), (1,3), dim_nums) + b\\n        pair_4 = conv_general_dilated(conv_out, W, stride, pad, (1,1), (1,4), dim_nums) + b\\n        pair_5 = conv_general_dilated(conv_out, W, stride, pad, (1,1), (1,5), dim_nums) + b\\n        pair_out = jnp.dstack([pair_1, pair_2, pair_3, pair_4, pair_5])\\n        pair_out = relu(pair_out)\\n\\n        # Forward pass.\\n        out = serial_apply(serial_params, pair_out)\\n        return out\\n\\n    return init_fun, apply_fun\\n\\n#\\n\\n# if __name__ == \"__main__\":\\n#     rng = jax.random.PRNGKey(0)\\n#     input_shape = (3, 18, 1)\\n#     init_fun, apply_fun = conv_net()\\n#     out_shape, params = init_fun(rng, input_shape)\\n#     # print(\"PARAMS:\")\\n#     # print(params, \"\\\\n\\\\n\")\\n\\n#     inputs = np.array([[i ** 1.0] for i in range(3*18)], dtype=np.float32).reshape(1, 3, 18, 1)\\n\\n#     # print(\"inputs:\\\\n\", inputs)\\n#     vals = apply_fun(params, inputs)',\n",
              " 'cube_model_naive.py': b'import numpy as np\\nfrom collections import namedtuple\\n\\n\\nclass Cube:\\n    \"\"\"\\n    A concrete class representation of a Rubik\\'s Cube.\\n    The state of the cube is represented as a flattened 2D matrix.\\n\\n    0 0 0 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5     # 0 is orange\\n    0 0 0 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5     # 1 is green  \\n    0 0 0 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5     # 2 is red\\n                                            # 3 is white\\n                                            # 4 is blue\\n                                            # 5 is yellow\\n    \\n    Every color number is additionally represented as a one-hot\\n    vector, thus making the state a 3D tensor of shape (3, 18, 6).\\n    \"\"\"\\n    #----------- class variables ----------#\\n    Side = namedtuple(\"Side\", [\"LEFT\", \"FRONT\", \"RIGHT\", \"BACK\", \"UP\", \"DOWN\"])(\\n                                0, 1, 2, 3, 4, 5)\\n    Direction = namedtuple(\"Direction\", [\"ANTI_CLOCK\", \"CLOCK\"])(0, 1)\\n    Color = namedtuple(\"Color\", [\"ORANGE\", \"GREEN\", \"RED\", \"WHITE\", \"BLUE\", \"YELLOW\"])(\\n                                0, 1, 2, 3, 4, 5)\\n\\n    num_actions = len(Side) * len(Direction)\\n    action_space = np.arange(num_actions, dtype=int)\\n    terminal_state = np.hstack([np.full((3,3), _col) for _col in Color])\\n    terminal_state = np.array(np.expand_dims(\\n                                    terminal_state, -1) == np.arange(len(Color)),\\n                                    dtype=np.float32)\\n\\n    #------------ class methods -----------#\\n    @classmethod\\n    def is_terminal(cls, state):\\n        \"\"\" Return True if the state is the terminal state for the environment.\\n        \\n        @param state (Array): A state of the environment.\\n        @returns result (bool): True if the state is terminal for the environment.\\n                                Otherwise False.\\n        \"\"\"\\n        return np.all(state == cls.terminal_state)\\n\\n    @classmethod\\n    def reward(cls, state):\\n        \"\"\" Return the immediate reward on transition to state `state`.\\n\\n        @param state (Array): A state of the environment.\\n        @returns reward (int): Reward on trasition to state `state`.\\n        \"\"\"\\n        return 1 if cls.is_terminal(state) else -1\\n\\n    @classmethod\\n    def expand_state(cls, state):\\n        \"\"\" Given a state use the model of the environment to obtain\\n        the descendants of that state and their respective rewards.\\n        Return the descendants and the rewards.\\n\\n        @param state (Array): A state of the environment.\\n        @returns children (Array[state]): A numpy array of shape (num_acts, state.shape) giving\\n                                            the children of the input state.\\n        @returns rewards (Array): A numpy array of shape (num_acts, 1) containing the\\n                                    respective rewards.\\n        \"\"\"\\n        _cube = cls()\\n        _cube.state = state\\n        children = [_cube._take_action[act]() for act in cls.action_space]\\n        rewards = [cls.reward(_c) for _c in children]\\n        return np.stack(children), np.vstack(rewards)   # rewards shape is (num_acts, 1)\\n\\n    #----------- env initializer ----------#\\n    def __init__(self):\\n        \"\"\" Initialize an environment object. \"\"\"\\n        # Enumerate all valid actions from the action space.\\n        self._take_action = {0: self._left_anticlock,\\n                             1: self._left_clock,\\n                             2: self._front_anticlock,\\n                             3: self._front_clock,\\n                             4: self._right_anticlock,\\n                             5: self._right_clock,\\n                             6: self._back_anticlock,\\n                             7: self._back_clock,\\n                             8: self._up_anticlock,\\n                             9: self._up_clock,\\n                             10: self._down_anticlock,\\n                             11: self._down_clock}\\n\\n        # Set the current state to None.\\n        self._state = None\\n\\n        # Reset the environment.\\n        self.reset()\\n\\n    #---------- property methods ----------#\\n    @property\\n    def state(self):\\n        \"\"\" Return the current state of the environment. \"\"\"\\n        return self._state\\n\\n    @state.setter\\n    def state(self, new_state):\\n        \"\"\" Set the current state of the environment. \"\"\"\\n        self._state = new_state.copy()\\n\\n    #----------- public methods -----------#\\n    def step(self, act):\\n        \"\"\" Make a single step taking the specified action.\\n\\n        @param act (int): An integer value in the range [0, 12).\\n        @returns next_state (state): The next observed state after taking action `act`.\\n        @returns reward (int): An integer representing the reward after arriving at the next state.\\n        @returns done (bool): A boolen indicating whether this is a terminal state.\\n        \"\"\"\\n        if act not in self.action_space:\\n            raise Exception(\"Unknown action %s\", act)\\n\\n        # Observe the next state after taking action `act`.\\n        next_state = self._take_action[act]()\\n\\n        # Change the current state.\\n        self._state = next_state.copy()\\n\\n        # Check if this is the final state.\\n        done = self.is_solved()\\n        reward = self.reward(self._state)\\n\\n        return next_state, reward, done\\n\\n    def set_random_state(self, seed=None, scrambles=None):\\n        \"\"\" Set the current state of the environment to a random valid state. \"\"\"\\n        self.reset()\\n\\n        np.random.seed(seed=seed)\\n        if scrambles is None:\\n            scrambles = 100\\n        acts = np.random.randint(low=0, high=self.num_actions, size=scrambles)\\n        for a in acts:\\n            self.step(a)\\n\\n    def reset(self):\\n        \"\"\" Set the current state of the environment to the terminal state. \"\"\"\\n        self._state = self.terminal_state.copy()\\n\\n    def is_solved(self):\\n        \"\"\" Return True if the current state is the terminal state for the environment. \"\"\"\\n        return self.is_terminal(self._state)\\n\\n    #----------- private methods ----------#\\n    def _left_anticlock(self):\\n        \"\"\" Perform anti-clockwise rotation of the left side.\\n        Return the resulting state.\\n        \"\"\"\\n        # Unpack cube sides and rotation directions.\\n        l, f, r, b, u, d = self.Side\\n        a_cl, cl = self.Direction\\n        _ = (l, f, r, b, u, d, a_cl, cl)\\n        next_state = self._state.copy()\\n\\n        # Rotate the side in the given direction\\n        side, dir = l, a_cl\\n        next_state[:, 3*side:3*(side+1)] = np.rot90(self._state[:, 3*side:3*(side+1)], k=(-1)**dir)\\n\\n        # Rotate the adjecent rows and columns.\\n        next_state[:, 3 * u] = self._state[:, 3 * f]\\n        next_state[:, 3 * f] = self._state[:, 3 * d]\\n        next_state[:, 3 * d] = self._state[:, 3 * b + 2][::-1]      # flip\\n        next_state[:, 3 * b + 2] = self._state[:, 3 * u][::-1]      # flip\\n\\n        return next_state\\n\\n    def _left_clock(self):\\n        \"\"\" Perform clockwise rotation of the left side.\\n        Return the resulting state.\\n        \"\"\"\\n        # Unpack cube sides and rotation directions.\\n        l, f, r, b, u, d = self.Side\\n        a_cl, cl = self.Direction\\n        _ = (l, f, r, b, u, d, a_cl, cl)\\n        next_state = self._state.copy()\\n\\n        # Rotate the side in the given direction\\n        side, dir = l, cl\\n        next_state[:, 3*side:3*(side+1)] = np.rot90(self._state[:, 3*side:3*(side+1)], k=(-1)**dir)\\n\\n        # Rotate the adjecent rows and columns.\\n        next_state[:, 3 * f] = self._state[:, 3 * u]\\n        next_state[:, 3 * d] = self._state[:, 3 * f]\\n        next_state[:, 3 * u] = self._state[:, 3 * b + 2][::-1]      # flip\\n        next_state[:, 3 * b + 2] = self._state[:, 3 * d][::-1]      # flip\\n\\n        return next_state\\n\\n    def _front_anticlock(self):\\n        \"\"\" Perform anti-clockwise rotation of the front side.\\n        Return the resulting state.\\n        \"\"\"\\n        # Unpack cube sides and rotation directions.\\n        l, f, r, b, u, d = self.Side\\n        a_cl, cl = self.Direction\\n        _ = (l, f, r, b, u, d, a_cl, cl)\\n        next_state = self._state.copy()\\n\\n        # Rotate the side in the given direction\\n        side, dir = f, a_cl\\n        next_state[:, 3*side:3*(side+1)] = np.rot90(self._state[:, 3*side:3*(side+1)], k=(-1)**dir)\\n\\n        # Rotate the adjecent rows and columns.\\n        next_state[:, 3 * l + 2] = self._state[-1, 3 * u : 3 * (u + 1)][::-1]   # flip\\n        next_state[0, 3 * d : 3 * (d + 1)] = self._state[:, 3 * l + 2]\\n        next_state[:, 3 * r] = self._state[0, 3 * d : 3 * (d + 1)][::-1]        # flip\\n        next_state[-1, 3 * u : 3 * (u + 1)] = self._state[:, 3 * r]\\n\\n        return next_state\\n\\n    def _front_clock(self):\\n        \"\"\" Perform clockwise rotation of the front side.\\n        Return the resulting state.\\n        \"\"\"\\n        # Unpack cube sides and rotation directions.\\n        l, f, r, b, u, d = self.Side\\n        a_cl, cl = self.Direction\\n        _ = (l, f, r, b, u, d, a_cl, cl)\\n        next_state = self._state.copy()\\n\\n        # Rotate the side in the given direction\\n        side, dir = f, cl\\n        next_state[:, 3*side:3*(side+1)] = np.rot90(self._state[:, 3*side:3*(side+1)], k=(-1)**dir)\\n\\n        # Rotate the adjecent rows and columns.\\n        next_state[:, 3 * l + 2] = self._state[0, 3 * d : 3 * (d + 1)]\\n        next_state[0, 3 * d : 3 * (d + 1)] = self._state[:, 3 * r][::-1]        # flip\\n        next_state[:, 3 * r] = self._state[-1, 3 * u : 3 * (u + 1)]\\n        next_state[-1, 3 * u : 3 * (u + 1)] = self._state[:, 3 * l + 2][::-1]   # flip\\n\\n        return next_state\\n\\n    def _right_anticlock(self):\\n        \"\"\" Perform anti-clockwise rotation of the right side.\\n        Return the resulting state.\\n        \"\"\"\\n        # Unpack cube sides and rotation directions.\\n        l, f, r, b, u, d = self.Side\\n        a_cl, cl = self.Direction\\n        _ = (l, f, r, b, u, d, a_cl, cl)\\n        next_state = self._state.copy()\\n\\n        # Rotate the side in the given direction\\n        side, dir = r, a_cl\\n        next_state[:, 3*side:3*(side+1)] = np.rot90(self._state[:, 3*side:3*(side+1)], k=(-1)**dir)\\n\\n        # Rotate the adjecent rows and columns.\\n        next_state[:, 3 * f + 2] = self._state[:, 3 * u + 2]\\n        next_state[:, 3 * d + 2] = self._state[:, 3 * f + 2]\\n        next_state[:, 3 * b] = self._state[:, 3 * d + 2][::-1]      # flip\\n        next_state[:, 3 * u + 2] = self._state[:, 3 * b][::-1]      # flip\\n\\n        return next_state\\n\\n    def _right_clock(self):\\n        \"\"\" Perform clockwise rotation of the right side.\\n        Return the resulting state.\\n        \"\"\"\\n        # Unpack cube sides and rotation directions.\\n        l, f, r, b, u, d = self.Side\\n        a_cl, cl = self.Direction\\n        _ = (l, f, r, b, u, d, a_cl, cl)\\n        next_state = self._state.copy()\\n\\n        # Rotate the side in the given direction\\n        side, dir = r, cl\\n        next_state[:, 3*side:3*(side+1)] = np.rot90(self._state[:, 3*side:3*(side+1)], k=(-1)**dir)\\n\\n        # Rotate the adjecent rows and columns.\\n        next_state[:, 3 * f + 2] = self._state[:, 3 * d + 2]\\n        next_state[:, 3 * d + 2] = self._state[:, 3 * b][::-1]      # flip\\n        next_state[:, 3 * b] = self._state[:, 3 * u + 2][::-1]      # flip\\n        next_state[:, 3 * u + 2] = self._state[:, 3 * f + 2]\\n\\n        return next_state\\n\\n    def _back_anticlock(self):\\n        \"\"\" Perform anti-clockwise rotation of the back side.\\n        Return the resulting state.\\n        \"\"\"\\n        # Unpack cube sides and rotation directions.\\n        l, f, r, b, u, d = self.Side\\n        a_cl, cl = self.Direction\\n        _ = (l, f, r, b, u, d, a_cl, cl)\\n        next_state = self._state.copy()\\n\\n        # Rotate the side in the given direction\\n        side, dir = b, a_cl\\n        next_state[:, 3*side:3*(side+1)] = np.rot90(self._state[:, 3*side:3*(side+1)], k=(-1)**dir)\\n\\n        # Rotate the adjecent rows and columns.\\n        next_state[:, 3 * r + 2] = self._state[0, 3 * u : 3 * (u + 1)]\\n        next_state[-1, 3 * d : 3 * (d + 1)] = self._state[:, 3 * r + 2][::-1]       # flip\\n        next_state[:, 3 * l] = self._state[-1, 3 * d : 3 * (d + 1)]\\n        next_state[0, 3 * u : 3 * (u + 1)] = self._state[:, 3 * l][::-1]        # flip\\n\\n        return next_state\\n\\n    def _back_clock(self):\\n        \"\"\" Perform clockwise rotation of the back side.\\n        Return the resulting state.\\n        \"\"\"\\n        # Unpack cube sides and rotation directions.\\n        l, f, r, b, u, d = self.Side\\n        a_cl, cl = self.Direction\\n        _ = (l, f, r, b, u, d, a_cl, cl)\\n        next_state = self._state.copy()\\n\\n        # Rotate the side in the given direction\\n        side, dir = b, cl\\n        next_state[:, 3*side:3*(side+1)] = np.rot90(self._state[:, 3*side:3*(side+1)], k=(-1)**dir)\\n\\n        # Rotate the adjecent rows and columns.\\n        next_state[:, 3 * r + 2] = self._state[-1, 3 * d : 3 * (d + 1)][::-1]   # flip\\n        next_state[-1, 3 * d : 3 * (d + 1)] = self._state[:, 3 * l]\\n        next_state[:, 3 * l] = self._state[0, 3 * u : 3 * (u + 1)][::-1]        # flip\\n        next_state[0, 3 * u : 3 * (u + 1)] = (self._state[:, 3 * r + 2])\\n\\n        return next_state\\n\\n    def _up_anticlock(self):\\n        \"\"\" Perform anti-clockwise rotation of the up side.\\n        Return the resulting state.\\n        \"\"\"\\n        # Unpack cube sides and rotation directions.\\n        l, f, r, b, u, d = self.Side\\n        a_cl, cl = self.Direction\\n        _ = (l, f, r, b, u, d, a_cl, cl)\\n        next_state = self._state.copy()\\n\\n        # Rotate the side in the given direction\\n        side, dir = u, a_cl\\n        next_state[:, 3*side:3*(side+1)] = np.rot90(self._state[:, 3*side:3*(side+1)], k=(-1)**dir)\\n\\n        # Rotate the adjecent rows.\\n        next_state[0, 0:12] = np.roll(self._state[0, 0:12], shift=3, axis=0)\\n\\n        return next_state\\n\\n    def _up_clock(self):\\n        \"\"\" Perform clockwise rotation of the up side.\\n        Return the resulting state.\\n        \"\"\"\\n        # Unpack cube sides and rotation directions.\\n        l, f, r, b, u, d = self.Side\\n        a_cl, cl = self.Direction\\n        _ = (l, f, r, b, u, d, a_cl, cl)\\n        next_state = self._state.copy()\\n\\n        # Rotate the side in the given direction\\n        side, dir = u, cl\\n        next_state[:, 3*side:3*(side+1)] = np.rot90(self._state[:, 3*side:3*(side+1)], k=(-1)**dir)\\n\\n        # Rotate the adjecent rows.\\n        next_state[0, 0:12] = np.roll(self._state[0, 0:12], shift=-3, axis=0)\\n\\n        return next_state\\n\\n    def _down_anticlock(self):\\n        \"\"\" Perform anti-clockwise rotation of the down side.\\n        Return the resulting state.\\n        \"\"\"\\n        # Unpack cube sides and rotation directions.\\n        l, f, r, b, u, d = self.Side\\n        a_cl, cl = self.Direction\\n        _ = (l, f, r, b, u, d, a_cl, cl)\\n        next_state = self._state.copy()\\n\\n        # Rotate the side in the given direction\\n        side, dir = d, a_cl\\n        next_state[:, 3*side:3*(side+1)] = np.rot90(self._state[:, 3*side:3*(side+1)], k=(-1)**dir)\\n\\n        # Rotate the adjecent rows.\\n        next_state[-1, 0:12] = np.roll(self._state[-1, 0:12], shift=-3, axis=0)\\n\\n        return next_state\\n\\n    def _down_clock(self):\\n        \"\"\" Perform clockwise rotation of the down side.\\n        Return the resulting state.\\n        \"\"\"\\n        # Unpack cube sides and rotation directions.\\n        l, f, r, b, u, d = self.Side\\n        a_cl, cl = self.Direction\\n        _ = (l, f, r, b, u, d, a_cl, cl)\\n        next_state = self._state.copy()\\n\\n        # Rotate the side in the given direction\\n        side, dir = d, cl\\n        next_state[:, 3*side:3*(side+1)] = np.rot90(self._state[:, 3*side:3*(side+1)], k=(-1)**dir)\\n\\n        # Rotate the adjecent rows.\\n        next_state[-1, 0:12] = np.roll(self._state[-1, 0:12], shift=3, axis=0)\\n\\n        return next_state\\n\\n    #----------- static methods -----------#\\n    @staticmethod\\n    def plot_state(state):\\n        \"\"\"\\n        Given an environment state, prints the state in pretty form.\\n\\n              4 4 4                 # 0 is orange\\n              4 4 4                 # 1 is green\\n              4 4 4                 # 2 is red\\n        0 0 0 1 1 1 2 2 2 3 3 3     # 3 is white\\n        0 0 0 1 1 1 2 2 2 3 3 3     # 4 is blue\\n        0 0 0 1 1 1 2 2 2 3 3 3     # 5 is yellow\\n              5 5 5            \\n              5 5 5            \\n              5 5 5            \\n        \"\"\"\\n        result = np.zeros((9, 12), dtype=int)\\n        state = np.argmax(state, axis=-1)\\n        result[3:6, :] = state[:, :12]\\n        result[0:3, 3:6] = state[:, 12:15]\\n        result[6:9, 3:6] = state[:, 15:]\\n        print(result)\\n\\n#',\n",
              " 'train.py': b'import time\\nimport numpy as np\\nimport jax\\nimport jax.numpy as jnp\\nfrom jax.experimental import optimizers\\nfrom jax.tree_util import tree_flatten, tree_unflatten, tree_map\\nfrom functools import partial\\nfrom math import ceil\\n\\n\\n# from fcnn import fc_net as model_fn\\nfrom cnn import conv_net as model_fn\\n\\n\\n\\n#-------------------- data generation utilities --------------------#\\ndef expand_states(states, env):\\n    \"\"\" Given an array of states use the model of the environment to\\n    obtain the descendants of these states and their respective rewards.\\n    Return the descendants and the rewards.\\n\\n    @param states (Array[state]): A numpy array of valid states of the environment.\\n                                  The shape of the array is (N, state.shape),\\n                                  where N is the number of states.\\n    @param env (Cube Object): A Cube object representing the environment.\\n    @returns children (Array[state]): A numpy array giving the children of the input states\\n                                      The shape of the array is (N * num_acts, state.shape).\\n    @returns rewards (Array): A numpy array of shape (N, num_acts, 1) containing the\\n                              respective rewards.\\n    \"\"\"\\n    zipped = [env.expand_state(s) for s in states]\\n    children, rewards = list(zip(*zipped))\\n    children = np.vstack(children)\\n    rewards = np.stack(rewards)\\n    return children, rewards\\n\\n\\ndef generate_episodes(rng, env, episodes, k):\\n    \"\"\" Generate a random sequence of states starting from the solved state.\\n\\n    @param env (Cube Object): A Cube object representing the environment.\\n    @param episodes (int): Number of episodes to be created.\\n    @param k (int): Length of backward moves.\\n    @returns states (Array[state]): Sequence of generated states. The shape of the array\\n                                    is (episodes * k_max, state.shape).\\n    @returns weights (Array): Array of weights. w[i] corresponds to the weight of states[i].\\n    @returns children (Array[state]): Sequence of states corresponding to the children of\\n                                      each of the generated states. The shape of the array\\n                                      is (episodes * k_max * num_acts, state.shape).\\n    @returns rewards (Array): Array of rewards. rewards[i] corresponds to the immediate\\n                              reward on transition to state children[i]\\n    \"\"\"\\n    states, w = [], []\\n\\n    # Create an environtment.\\n    cube = env()\\n    num_actions = cube.num_actions\\n\\n    # Create `episodes` number of episodes.\\n    for _ in range(episodes):\\n        cube.reset()\\n        rng, sub_rng = jax.random.split(rng)\\n        actions = jax.random.randint(sub_rng, shape=(k,), minval=0, maxval=num_actions)\\n        states.extend((cube.step(act)[0] for act in actions))\\n        w.extend((1 / (d+1) for d in range(k)))\\n\\n    # Expand each state to obtain children and rewards.\\n    children, rewards = expand_states(states, env)\\n\\n    return jnp.array(states), jnp.array(w), jnp.array(children), jnp.array(rewards)\\n\\n\\ndef make_targets(children, rewards, params):\\n    \"\"\" Generate target values.\\n\\n    @param children (Array[state]): An array giving the children of the input states\\n                                    The shape of the array is (N * num_acts, state.shape).\\n    @param rewards (Array): A numpy array of shape (N, num_acts, 1) containing the\\n                            respective rewards.\\n    @param params (pytree): Model parameters for the prediction function.\\n    @returns vals (Array): An array giving the predicted values of each state.\\n    \"\"\"\\n    # Run the states through the network in batches.\\n    batch_size = 1000\\n    vals = []\\n    for i in range(ceil(children.shape[0] / batch_size)):\\n        v = apply_fun(params, children[i * batch_size : (i + 1) * batch_size])\\n        vals.append(v)\\n\\n    # Add rewards to make target values.\\n    vals = jnp.vstack(vals).reshape(rewards.shape) + rewards\\n    return jnp.max(vals, axis=1)\\n\\n\\ndef batch_generator(rng, data, batch_size):\\n    \"\"\" Yields random batches of data.\\n\\n    @param data (Dict):\\n    @param batch_size (int):\\n    @yields batch (Dict): Random batch of data of size `batch_size`.\\n    \"\"\"\\n    num_train = data[\"X\"].shape[0]\\n    while True:\\n        rng, sub_rng = jax.random.split(rng)\\n        idxs = jax.random.choice(sub_rng, jnp.arange(num_train), shape=(batch_size,), replace=False)\\n        yield (data[\"X\"][idxs],\\n               data[\"y\"][idxs],\\n               data[\"w\"][idxs])\\n\\n\\n\\n#------------------------ utility functions ------------------------#\\ndef fib(n, memo={}):\\n    \"\"\" Return the n-th Fibonacci number. \"\"\"\\n    if n == 0 or n == 1:\\n        memo[n] = 1\\n    elif n not in memo:\\n        memo[n] = fib(n-1, memo) + fib(n-2, memo)\\n    return memo[n]\\n\\n\\ndef reverse_fib(n):\\n    \"\"\" Return the index of the greatest number from the Fibonacci sequence,\\n    that is smaller than or equal to n. \"\"\"\\n    i = 0\\n    while fib(i+1) <= n:\\n        i += 1\\n    return i\\n\\n\\n\\n#-------------------- optimizer and LR schedule --------------------#\\nstep_size = 1e-3\\ndecay_rate = 0.0\\ndecay_steps = 1\\nstep_fn = optimizers.inverse_time_decay(step_size=step_size,\\n                                        decay_rate=decay_rate,\\n                                        decay_steps=decay_steps)\\nopt_init, opt_update, get_params = optimizers.adam(step_size=step_fn)\\n\\n\\n\\n#-------------------- params training utilities --------------------#\\ninit_fun, apply_fun = model_fn()\\n\\n\\n@jax.jit\\ndef l2_regularizer(params, reg=1e-4):\\n    \"\"\" Return the L2 regularization loss. \"\"\"\\n    leaves, _ = tree_flatten(params)\\n    return reg * sum(jnp.vdot(x, x) for x in leaves)\\n\\n\\n@jax.jit\\ndef loss_fn(params, batch):\\n    \"\"\" Return the total loss computed for a given batch. \"\"\"\\n    X, y, w = batch\\n    vals = apply_fun(params, X)\\n    mse_loss = jnp.sum(((vals - y) ** 2).squeeze() * w)\\n    l2_loss = l2_regularizer(params)\\n    return mse_loss + l2_loss\\n\\n\\n@jax.jit\\ndef update(i, opt_state, batch):\\n    \"\"\" Perform backpropagation and parameter update. \"\"\"\\n    params = get_params(opt_state)\\n    loss, grads = jax.value_and_grad(loss_fn)(params, batch)\\n    # clipped_grads = optimizers.clip_grads(grads, clip_norm)   # norm clipping produces very big differences when jit.\\n    clipped_grads = tree_map(lambda w: jnp.clip(w, -10.0, 10.0), grads)\\n    return loss, opt_update(i, clipped_grads, opt_state)\\n\\n\\ndef train(rng, env, batch_size=128, num_epochs=5, num_iterations=21,\\n          num_samples=100, print_every=10, episodes=100, k_min=1, k_max=25,\\n          verbose=False, params_save_path=None):\\n    \"\"\"\\n    Train the model function by generating simulations of random-play.\\n    On every epoch generate a new simulation and run multiple iterations.\\n    On every iteration evaluate the targets using the most recent model parameters\\n    and run multiple times through the dataset.\\n    At the end of every epoch check the performance and store the best performing params.\\n    If the performance drops then decay the step size parameter.\\n\\n    @param rng (PRNGKey): A pseudo-random number generator.\\n    @param env (Cube Object): A Cube object representing the environment.\\n    @param batch_size (int): Size of minibatches used to compute loss and gradient during training.         [optional]\\n    @param num_epochs (int): The number of epochs to run for during training.                               [optional]\\n    @param num_iterations (int): The number of iterations through the generated episodes.                   [optional]\\n    @param num_samples (int): The number of times the dataset is reused.                                    [optional]\\n    @param print_every (int): An integer. Training progress will be printed every `print_every` iterations. [optional]\\n    @param episodes (int): Number of episodes to be created.                                                [optional]\\n    @param k_min (int): Minimum length of sequence of backward moves.                                       [optional]\\n    @param k_max (int): Maximum length of sequence of backward moves.                                       [optional]\\n    @param clip_norm (float): A scalar for gradient clipping.                                               [optional]\\n    @param verbose (bool): If set to false then no output will be printed during training.                  [optional]\\n    @param params_save_path (str): File path to save the model parameters.                                  [optional]\\n    @returns params (pytree): The best model parameters obatained during training.                          [optional]\\n    @returns loss_history (List): A list containing the mean loss computed during each iteration.           [optional]\\n    \"\"\"\\n    loss_history = []\\n\\n    # Initialize model parameters and optimizer state.\\n    rng, init_rng = jax.random.split(rng)\\n    input_shape = env.terminal_state.shape\\n    params = None\\n    if params_save_path is None:\\n        _, params = init_fun(init_rng, input_shape)\\n    else:\\n        params = list(jnp.load(params_save_path, allow_pickle=True))\\n\\n    # Begin training.\\n    for e in range(num_epochs):\\n        tic = time.time()\\n        opt_state = opt_init(params)\\n\\n        # Generate data from random-play using the environment.\\n        rng, sub_rng = jax.random.split(rng)\\n        # k = max(k_min, min(k_max, reverse_fib(e + 1)))  # Slowly increase the length of each episode starting from k_min.\\n        k = k_max\\n        states, w, children, rewards = generate_episodes(sub_rng, env, episodes, k)\\n\\n        # Train the model on the generated data. Periodically recompute the target values.\\n        epoch_mean_loss = 0.0\\n        for it in range(num_iterations):\\n            tic_it = time.time()\\n\\n            # Make targets for the generated episodes using the most recent params and build a batch generator.\\n            params = get_params(opt_state)\\n            tgt_vals = make_targets(children, rewards, params)\\n            data = {\"X\" : states, \"y\" : tgt_vals, \"w\" : w}\\n            rng, sub_rng = jax.random.split(rng)\\n            train_batches = batch_generator(sub_rng, data, batch_size)\\n\\n            # Run through the dataset and update model params.\\n            total_loss = 0.0\\n            for _ in range(num_samples):\\n                batch = next(train_batches)\\n                loss, opt_state = update(e, opt_state, batch)\\n                total_loss += loss\\n\\n            # Book-keeping.\\n            iter_mean_loss = total_loss / num_samples\\n            epoch_mean_loss = (it * epoch_mean_loss + iter_mean_loss) / (it + 1)\\n            loss_history.append(iter_mean_loss)\\n\\n            # Printout results.\\n            toc_it = time.time()\\n            if it % print_every == 0 and verbose:\\n                print(\"\\\\t(Iteration({}/{}) took {:.3f} seconds) iter_mean_loss = {:.3f}\".format(\\n                                                        it + 1, num_iterations, (toc_it-tic_it), iter_mean_loss))\\n        # Store the model parameters.\\n        if params_save_path is not None:\\n            jnp.save(params_save_path, params)\\n\\n        # Record the time needed for a single epoch.\\n        toc = time.time()\\n\\n        # Printout results.\\n        if verbose:\\n            print(\"(Epoch ({}/{}) took {:.3f} seconds), epoch_mean_loss = {:.3f}\".format(\\n                                                        e + 1, num_epochs, (toc-tic), epoch_mean_loss))\\n    return params, loss_history\\n\\n\\n\\nif __name__ == \"__main__\":\\n    from cube_model_naive import Cube as env\\n\\n    seed = 0\\n    rng = jax.random.PRNGKey(seed=seed)\\n\\n    ### Run training.\\n    params, loss_history = train(rng, env,\\n                                 batch_size=128,\\n                                 num_epochs=1,\\n                                 num_iterations=1,\\n                                 num_samples=50,\\n                                 print_every=1,\\n                                 episodes=1000,\\n                                 k_max=15,\\n                                 verbose=True,\\n                                 params_save_path=None)\\n\\n#'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja8q2_TV33QU"
      },
      "source": [
        "import time\n",
        "import jax\n",
        "from cube_model_naive import Cube as env\n",
        "from train import train"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvUfP4TF35KW"
      },
      "source": [
        "seed = 0\n",
        "rng = jax.random.PRNGKey(seed=seed)\n",
        "\n",
        "# GLOBAL VARIABLES IN THE SCRIPT\n",
        "########## >>>>>   step_size = 1e-3\n",
        "########## >>>>>   decay_rate = 0.0\n",
        "########## >>>>>   reg = 1e-4\n",
        "########## >>>>>   clip_max_grad = 10.0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk5JCfQ037FH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bad243de-e8fa-4e22-990d-48fadc5ca77d"
      },
      "source": [
        "tic = time.time()\n",
        "\n",
        "params, loss_history = train(rng, env,\n",
        "                             batch_size=128,\n",
        "                             num_epochs=30,\n",
        "                             num_iterations=41,\n",
        "                             num_samples=1000,\n",
        "                             print_every=20,\n",
        "                             episodes=1000,\n",
        "                             k_max=15,\n",
        "                             verbose=True,\n",
        "                             params_save_path=None)\n",
        "\n",
        "toc = time.time()\n",
        "print(\"\\n TRAINING TOOK {:.2f} minutes\".format((toc - tic) / 60.0))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t(Iteration(1/41) took 25.848 seconds) iter_mean_loss = 0.694\n",
            "\t(Iteration(21/41) took 12.137 seconds) iter_mean_loss = 1.386\n",
            "\t(Iteration(41/41) took 12.396 seconds) iter_mean_loss = 0.805\n",
            "(Epoch (1/30) took 526.295 seconds), epoch_mean_loss = 1.362\n",
            "\t(Iteration(1/41) took 12.268 seconds) iter_mean_loss = 2.528\n",
            "\t(Iteration(21/41) took 12.371 seconds) iter_mean_loss = 0.645\n",
            "\t(Iteration(41/41) took 12.151 seconds) iter_mean_loss = 0.531\n",
            "(Epoch (2/30) took 521.121 seconds), epoch_mean_loss = 0.836\n",
            "\t(Iteration(1/41) took 12.371 seconds) iter_mean_loss = 2.085\n",
            "\t(Iteration(21/41) took 13.161 seconds) iter_mean_loss = 0.710\n",
            "\t(Iteration(41/41) took 12.438 seconds) iter_mean_loss = 0.602\n",
            "(Epoch (3/30) took 520.786 seconds), epoch_mean_loss = 0.822\n",
            "\t(Iteration(1/41) took 12.268 seconds) iter_mean_loss = 2.143\n",
            "\t(Iteration(21/41) took 11.794 seconds) iter_mean_loss = 0.657\n",
            "\t(Iteration(41/41) took 11.909 seconds) iter_mean_loss = 0.542\n",
            "(Epoch (4/30) took 509.945 seconds), epoch_mean_loss = 0.795\n",
            "\t(Iteration(1/41) took 12.392 seconds) iter_mean_loss = 1.786\n",
            "\t(Iteration(21/41) took 11.972 seconds) iter_mean_loss = 0.563\n",
            "\t(Iteration(41/41) took 12.465 seconds) iter_mean_loss = 0.499\n",
            "(Epoch (5/30) took 516.094 seconds), epoch_mean_loss = 0.719\n",
            "\t(Iteration(1/41) took 12.407 seconds) iter_mean_loss = 1.662\n",
            "\t(Iteration(21/41) took 11.974 seconds) iter_mean_loss = 0.529\n",
            "\t(Iteration(41/41) took 11.985 seconds) iter_mean_loss = 0.471\n",
            "(Epoch (6/30) took 505.996 seconds), epoch_mean_loss = 0.621\n",
            "\t(Iteration(1/41) took 12.148 seconds) iter_mean_loss = 1.538\n",
            "\t(Iteration(21/41) took 12.095 seconds) iter_mean_loss = 0.519\n",
            "\t(Iteration(41/41) took 12.540 seconds) iter_mean_loss = 0.471\n",
            "(Epoch (7/30) took 515.448 seconds), epoch_mean_loss = 0.632\n",
            "\t(Iteration(1/41) took 12.516 seconds) iter_mean_loss = 1.484\n",
            "\t(Iteration(21/41) took 12.300 seconds) iter_mean_loss = 0.567\n",
            "\t(Iteration(41/41) took 12.452 seconds) iter_mean_loss = 0.532\n",
            "(Epoch (8/30) took 519.577 seconds), epoch_mean_loss = 0.681\n",
            "\t(Iteration(1/41) took 12.831 seconds) iter_mean_loss = 1.550\n",
            "\t(Iteration(21/41) took 12.347 seconds) iter_mean_loss = 0.571\n",
            "\t(Iteration(41/41) took 12.010 seconds) iter_mean_loss = 0.560\n",
            "(Epoch (9/30) took 516.968 seconds), epoch_mean_loss = 0.738\n",
            "\t(Iteration(1/41) took 11.975 seconds) iter_mean_loss = 1.545\n",
            "\t(Iteration(21/41) took 12.194 seconds) iter_mean_loss = 0.673\n",
            "\t(Iteration(41/41) took 12.812 seconds) iter_mean_loss = 0.636\n",
            "(Epoch (10/30) took 514.563 seconds), epoch_mean_loss = 0.800\n",
            "\t(Iteration(1/41) took 12.092 seconds) iter_mean_loss = 1.551\n",
            "\t(Iteration(21/41) took 12.554 seconds) iter_mean_loss = 0.643\n",
            "\t(Iteration(41/41) took 12.341 seconds) iter_mean_loss = 0.583\n",
            "(Epoch (11/30) took 512.432 seconds), epoch_mean_loss = 0.809\n",
            "\t(Iteration(1/41) took 12.363 seconds) iter_mean_loss = 1.687\n",
            "\t(Iteration(21/41) took 12.089 seconds) iter_mean_loss = 0.746\n",
            "\t(Iteration(41/41) took 12.150 seconds) iter_mean_loss = 0.621\n",
            "(Epoch (12/30) took 502.524 seconds), epoch_mean_loss = 0.830\n",
            "\t(Iteration(1/41) took 12.154 seconds) iter_mean_loss = 1.553\n",
            "\t(Iteration(21/41) took 12.295 seconds) iter_mean_loss = 0.642\n",
            "\t(Iteration(41/41) took 12.603 seconds) iter_mean_loss = 0.563\n",
            "(Epoch (13/30) took 505.525 seconds), epoch_mean_loss = 0.773\n",
            "\t(Iteration(1/41) took 12.412 seconds) iter_mean_loss = 1.473\n",
            "\t(Iteration(21/41) took 12.177 seconds) iter_mean_loss = 0.684\n",
            "\t(Iteration(41/41) took 12.316 seconds) iter_mean_loss = 0.595\n",
            "(Epoch (14/30) took 513.194 seconds), epoch_mean_loss = 0.767\n",
            "\t(Iteration(1/41) took 12.737 seconds) iter_mean_loss = 1.440\n",
            "\t(Iteration(21/41) took 12.121 seconds) iter_mean_loss = 0.547\n",
            "\t(Iteration(41/41) took 12.372 seconds) iter_mean_loss = 0.483\n",
            "(Epoch (15/30) took 513.733 seconds), epoch_mean_loss = 0.681\n",
            "\t(Iteration(1/41) took 12.675 seconds) iter_mean_loss = 1.321\n",
            "\t(Iteration(21/41) took 11.831 seconds) iter_mean_loss = 0.543\n",
            "\t(Iteration(41/41) took 13.093 seconds) iter_mean_loss = 0.532\n",
            "(Epoch (16/30) took 513.095 seconds), epoch_mean_loss = 0.666\n",
            "\t(Iteration(1/41) took 12.322 seconds) iter_mean_loss = 1.381\n",
            "\t(Iteration(21/41) took 12.351 seconds) iter_mean_loss = 0.526\n",
            "\t(Iteration(41/41) took 12.090 seconds) iter_mean_loss = 0.477\n",
            "(Epoch (17/30) took 524.255 seconds), epoch_mean_loss = 0.616\n",
            "\t(Iteration(1/41) took 13.157 seconds) iter_mean_loss = 1.299\n",
            "\t(Iteration(21/41) took 12.543 seconds) iter_mean_loss = 0.509\n",
            "\t(Iteration(41/41) took 12.450 seconds) iter_mean_loss = 0.426\n",
            "(Epoch (18/30) took 520.765 seconds), epoch_mean_loss = 0.564\n",
            "\t(Iteration(1/41) took 12.068 seconds) iter_mean_loss = 1.281\n",
            "\t(Iteration(21/41) took 12.385 seconds) iter_mean_loss = 0.501\n",
            "\t(Iteration(41/41) took 12.612 seconds) iter_mean_loss = 0.485\n",
            "(Epoch (19/30) took 515.991 seconds), epoch_mean_loss = 0.557\n",
            "\t(Iteration(1/41) took 12.332 seconds) iter_mean_loss = 1.245\n",
            "\t(Iteration(21/41) took 12.515 seconds) iter_mean_loss = 0.420\n",
            "\t(Iteration(41/41) took 12.439 seconds) iter_mean_loss = 0.397\n",
            "(Epoch (20/30) took 511.210 seconds), epoch_mean_loss = 0.545\n",
            "\t(Iteration(1/41) took 12.542 seconds) iter_mean_loss = 1.192\n",
            "\t(Iteration(21/41) took 12.581 seconds) iter_mean_loss = 0.453\n",
            "\t(Iteration(41/41) took 13.020 seconds) iter_mean_loss = 0.398\n",
            "(Epoch (21/30) took 527.100 seconds), epoch_mean_loss = 0.541\n",
            "\t(Iteration(1/41) took 12.366 seconds) iter_mean_loss = 1.194\n",
            "\t(Iteration(21/41) took 12.661 seconds) iter_mean_loss = 0.442\n",
            "\t(Iteration(41/41) took 11.804 seconds) iter_mean_loss = 0.375\n",
            "(Epoch (22/30) took 530.142 seconds), epoch_mean_loss = 0.507\n",
            "\t(Iteration(1/41) took 12.256 seconds) iter_mean_loss = 1.150\n",
            "\t(Iteration(21/41) took 12.196 seconds) iter_mean_loss = 0.370\n",
            "\t(Iteration(41/41) took 12.231 seconds) iter_mean_loss = 0.344\n",
            "(Epoch (23/30) took 509.624 seconds), epoch_mean_loss = 0.461\n",
            "\t(Iteration(1/41) took 13.011 seconds) iter_mean_loss = 1.151\n",
            "\t(Iteration(21/41) took 12.655 seconds) iter_mean_loss = 0.345\n",
            "\t(Iteration(41/41) took 12.077 seconds) iter_mean_loss = 0.339\n",
            "(Epoch (24/30) took 504.869 seconds), epoch_mean_loss = 0.442\n",
            "\t(Iteration(1/41) took 12.613 seconds) iter_mean_loss = 1.152\n",
            "\t(Iteration(21/41) took 11.601 seconds) iter_mean_loss = 0.329\n",
            "\t(Iteration(41/41) took 12.388 seconds) iter_mean_loss = 0.282\n",
            "(Epoch (25/30) took 509.555 seconds), epoch_mean_loss = 0.417\n",
            "\t(Iteration(1/41) took 12.181 seconds) iter_mean_loss = 1.076\n",
            "\t(Iteration(21/41) took 12.430 seconds) iter_mean_loss = 0.326\n",
            "\t(Iteration(41/41) took 11.834 seconds) iter_mean_loss = 0.304\n",
            "(Epoch (26/30) took 501.121 seconds), epoch_mean_loss = 0.392\n",
            "\t(Iteration(1/41) took 12.181 seconds) iter_mean_loss = 1.109\n",
            "\t(Iteration(21/41) took 11.981 seconds) iter_mean_loss = 0.321\n",
            "\t(Iteration(41/41) took 11.878 seconds) iter_mean_loss = 0.295\n",
            "(Epoch (27/30) took 502.931 seconds), epoch_mean_loss = 0.395\n",
            "\t(Iteration(1/41) took 12.210 seconds) iter_mean_loss = 1.044\n",
            "\t(Iteration(21/41) took 12.348 seconds) iter_mean_loss = 0.351\n",
            "\t(Iteration(41/41) took 11.928 seconds) iter_mean_loss = 0.334\n",
            "(Epoch (28/30) took 507.709 seconds), epoch_mean_loss = 0.421\n",
            "\t(Iteration(1/41) took 12.120 seconds) iter_mean_loss = 1.160\n",
            "\t(Iteration(21/41) took 11.826 seconds) iter_mean_loss = 0.356\n",
            "\t(Iteration(41/41) took 12.965 seconds) iter_mean_loss = 0.344\n",
            "(Epoch (29/30) took 511.879 seconds), epoch_mean_loss = 0.441\n",
            "\t(Iteration(1/41) took 12.442 seconds) iter_mean_loss = 1.145\n",
            "\t(Iteration(21/41) took 11.792 seconds) iter_mean_loss = 0.434\n",
            "\t(Iteration(41/41) took 11.855 seconds) iter_mean_loss = 0.408\n",
            "(Epoch (30/30) took 507.826 seconds), epoch_mean_loss = 0.497\n",
            "\n",
            " TRAINING TOOK 256.91 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3K5h8gIjGXy"
      },
      "source": [
        "root = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "params_save_path = root + \"params_cnn.npy\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGIFTcGEYukl"
      },
      "source": [
        "jax.numpy.save(params_save_path, params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1rpmlAypOWS"
      },
      "source": [
        "params = jax.numpy.load(params_save_path, allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpoBHShSRdpJ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import Astar\n",
        "\n",
        "# from fcnn import fc_net as model_fn\n",
        "from cnn import conv_net as model_fn\n",
        "\n",
        "init_fun, apply_fun = model_fn()\n",
        "\n",
        "cube = env()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaHI3RIT39j5",
        "outputId": "59701244-efb8-4e88-8344-4d4f5bf2b26e"
      },
      "source": [
        "times_solved = 0\n",
        "for it in range(100):\n",
        "  cube.set_random_state(seed=it, scrambles=10)\n",
        "  for s in range(100):\n",
        "    children, _ = env.expand_state(cube._state)\n",
        "    vals = apply_fun(params, children)\n",
        "    act = int(np.argmax(vals))\n",
        "    cube.step(act)\n",
        "\n",
        "    if cube.is_solved():\n",
        "      times_solved += 1\n",
        "      print(\"solved the cube at step {} in iteration {}\".format(s + 1, it + 1))\n",
        "      break\n",
        "print(\"Managed to solve 10-scrambled cube {} times\".format(times_solved))\n",
        "\n",
        "times_solved = 0\n",
        "for it in range(100):\n",
        "  cube.set_random_state(seed=it, scrambles=5)\n",
        "  for s in range(100):\n",
        "    children, _ = env.expand_state(cube._state)\n",
        "    vals = apply_fun(params, children)\n",
        "    act = int(np.argmax(vals))\n",
        "    cube.step(act)\n",
        "\n",
        "    if cube.is_solved():\n",
        "      times_solved += 1\n",
        "      print(\"solved the cube at step {} in iteration {}\".format(s + 1, it + 1))\n",
        "      break\n",
        "print(\"Managed to solve 5-scrambled cube {} times\".format(times_solved))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "solved the cube at step 6 in iteration 15\n",
            "solved the cube at step 6 in iteration 95\n",
            "Managed to solve 10-scrambled cube 2 times\n",
            "solved the cube at step 1 in iteration 15\n",
            "solved the cube at step 5 in iteration 46\n",
            "solved the cube at step 3 in iteration 91\n",
            "solved the cube at step 5 in iteration 95\n",
            "Managed to solve 5-scrambled cube 4 times\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx0T5H3VZOtg",
        "outputId": "b0de70b0-dfd1-461e-8e40-225ae4369ab4"
      },
      "source": [
        "num_cubes = 100\n",
        "scrambles = 5\n",
        "start = time.time()\n",
        "solved = 0\n",
        "for it in range(num_cubes):\n",
        "  cube.set_random_state(seed=it, scrambles=scrambles)\n",
        "  res = Astar.astar(cube._state, params, apply_fun)\n",
        "  if res != ():\n",
        "    solved += 1\n",
        "end = time.time()\n",
        "print(\"Solved {}/{} cubes scrambled {} times in {:.0f} seconds.\".format(solved, num_cubes, scrambles, (end-start)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solved 100/100 cubes scrambled 5 times in 18 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHeZ1IMsRHiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64cae70c-67c5-4e8b-b4c3-f18c9c1832fe"
      },
      "source": [
        "num_cubes = 100\n",
        "scrambles = 10\n",
        "start = time.time()\n",
        "solved = 0\n",
        "for it in range(num_cubes):\n",
        "  cube.set_random_state(seed=it, scrambles=scrambles)\n",
        "  res = Astar.astar(cube._state, params, apply_fun)\n",
        "  if res != ():\n",
        "    solved += 1\n",
        "end = time.time()\n",
        "print(\"Solved {}/{} cubes scrambled {} times in {:.0f} seconds.\".format(solved, num_cubes, scrambles, (end-start)))\n",
        "\n",
        "\n",
        "num_cubes = 100\n",
        "scrambles = 15\n",
        "start = time.time()\n",
        "solved = 0\n",
        "for it in range(num_cubes):\n",
        "  cube.set_random_state(seed=it, scrambles=scrambles)\n",
        "  res = Astar.astar(cube._state, params, apply_fun)\n",
        "  if res != ():\n",
        "    solved += 1\n",
        "end = time.time()\n",
        "print(\"Solved {}/{} cubes scrambled {} times in {:.0f} seconds.\".format(solved, num_cubes, scrambles, (end-start)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solved 69/100 cubes scrambled 10 times in 434 seconds.\n",
            "Solved 16/100 cubes scrambled 15 times in 873 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHMcTUI-YJEf",
        "outputId": "51f81444-f36c-46a4-a482-23caf3d64418"
      },
      "source": [
        "tic = time.time()\n",
        "\n",
        "params, loss_history = train(rng, env,\n",
        "                             batch_size=128,\n",
        "                             num_epochs=30,\n",
        "                             num_iterations=41,\n",
        "                             num_samples=1000,\n",
        "                             print_every=20,\n",
        "                             episodes=1000,\n",
        "                             k_max=15,\n",
        "                             verbose=True,\n",
        "                             params_save_path=params_save_path)\n",
        "\n",
        "toc = time.time()\n",
        "print(\"\\n TRAINING TOOK {:.2f} minutes\".format((toc - tic) / 60.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t(Iteration(1/41) took 26.918 seconds) iter_mean_loss = 1.269\n",
            "\t(Iteration(21/41) took 12.440 seconds) iter_mean_loss = 0.471\n",
            "\t(Iteration(41/41) took 12.100 seconds) iter_mean_loss = 0.441\n",
            "(Epoch (1/30) took 538.424 seconds), epoch_mean_loss = 0.568\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t(Iteration(1/41) took 12.466 seconds) iter_mean_loss = 1.347\n",
            "\t(Iteration(21/41) took 11.919 seconds) iter_mean_loss = 0.497\n",
            "\t(Iteration(41/41) took 11.836 seconds) iter_mean_loss = 0.449\n",
            "(Epoch (2/30) took 504.928 seconds), epoch_mean_loss = 0.595\n",
            "\t(Iteration(1/41) took 11.838 seconds) iter_mean_loss = 1.351\n",
            "\t(Iteration(21/41) took 11.731 seconds) iter_mean_loss = 0.491\n",
            "\t(Iteration(41/41) took 11.737 seconds) iter_mean_loss = 0.427\n",
            "(Epoch (3/30) took 493.565 seconds), epoch_mean_loss = 0.590\n",
            "\t(Iteration(1/41) took 11.816 seconds) iter_mean_loss = 1.389\n",
            "\t(Iteration(21/41) took 11.944 seconds) iter_mean_loss = 0.489\n",
            "\t(Iteration(41/41) took 11.766 seconds) iter_mean_loss = 0.425\n",
            "(Epoch (4/30) took 486.718 seconds), epoch_mean_loss = 0.590\n",
            "\t(Iteration(1/41) took 11.526 seconds) iter_mean_loss = 1.341\n",
            "\t(Iteration(21/41) took 11.739 seconds) iter_mean_loss = 0.487\n",
            "\t(Iteration(41/41) took 11.522 seconds) iter_mean_loss = 0.432\n",
            "(Epoch (5/30) took 484.417 seconds), epoch_mean_loss = 0.563\n",
            "\t(Iteration(1/41) took 11.862 seconds) iter_mean_loss = 1.382\n",
            "\t(Iteration(21/41) took 11.587 seconds) iter_mean_loss = 0.483\n",
            "\t(Iteration(41/41) took 12.492 seconds) iter_mean_loss = 0.422\n",
            "(Epoch (6/30) took 484.720 seconds), epoch_mean_loss = 0.557\n",
            "\t(Iteration(1/41) took 11.614 seconds) iter_mean_loss = 1.297\n",
            "\t(Iteration(21/41) took 11.734 seconds) iter_mean_loss = 0.434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugR2Q5JeY041"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}